{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc959af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import re\n",
    "import html\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from requests import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef119def",
   "metadata": {},
   "outputs": [],
   "source": [
    "roman_dict = {\n",
    "        '1': \"I\",\n",
    "        '1A': \"I A\",\n",
    "        '1B': \"I B\",\n",
    "        '1C': \"I C\",\n",
    "        '2': \"II\",\n",
    "        '3': \"III\",\n",
    "        '4': \"IV\",\n",
    "        '5': \"V\",\n",
    "        '6': \"VI\",\n",
    "        '7': \"VII\",\n",
    "        '7A': \"VII A\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1930f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_indices(file_text, substring):\n",
    "    try:\n",
    "        item_no = substring.split()[1].strip('.')\n",
    "        pattern = r'(?i)(?:^|\\n)(I[\\s\\n]*t[\\s\\n]*e[\\s\\n]*m|I[\\s\\n]*t[\\s\\n]*e[\\s\\n]*m[\\s\\n]*s[\\s\\n]*)\\s*{}\\b\\s*[.:\\\\-]*'\n",
    "        pattern = pattern.format(item_no)\n",
    "        matches = [match.start() for match in re.finditer(pattern, file_text, re.MULTILINE)]\n",
    "        if matches==[]:\n",
    "            roman_no = roman_dict[item_no]\n",
    "            pattern = r'(?i)(?:^|\\n)(I[\\s\\n]*t[\\s\\n]*e[\\s\\n]*m|I[\\s\\n]*t[\\s\\n]*e[\\s\\n]*m[\\s\\n]*s[\\s\\n]*)\\s*{}\\b\\s*[.:\\\\-]*'\n",
    "            pattern = pattern.format(roman_no)\n",
    "            matches = [match.start() for match in re.finditer(pattern, file_text, re.MULTILINE)]\n",
    "    except:\n",
    "        matches = []\n",
    "    return matches\n",
    "\n",
    "def find_item_text(file_text, substring, index):\n",
    "    item_indices = find_all_indices(file_text, substring)\n",
    "    if substring=='ITEM 1.' and index!=0:\n",
    "        item_indices = [i for i in item_indices if i >= index]\n",
    "    elif substring!='ITEM 1.':\n",
    "        item_indices = [i for i in item_indices if i >= index]\n",
    "\n",
    "    if item_indices:\n",
    "        for start in item_indices:\n",
    "            item_start_index = start\n",
    "            startcheck = start\n",
    "            if file_text[item_start_index]=='\\n':\n",
    "                startcheck +=1\n",
    "            lines = file_text.splitlines()\n",
    "            matching_line = None\n",
    "            current_index = 0\n",
    "            for i, line in enumerate(lines):\n",
    "                line_length = len(line)\n",
    "                if i < len(lines) - 1:\n",
    "                    line_length += 1  \n",
    "                if current_index <= startcheck < current_index + line_length:\n",
    "                    matching_line = line\n",
    "                    break\n",
    "                current_index += line_length\n",
    "            line = matching_line\n",
    "            if line==None:\n",
    "                pass\n",
    "            elif '\"' not in line and '“' not in line and '”' not in line and '...' not in line and ',' not in line:\n",
    "                item_start_index = start\n",
    "                break\n",
    "        pattern = re.compile(r'(?i)(?:^|\\n)(I[\\s\\n]*t[\\s\\n]*e[\\s\\n]*m|I[\\s\\n]*t[\\s\\n]*e[\\s\\n]*m[\\s\\n]*s[\\s\\n]*)\\s*[0-9A-C]+\\s*[.:\\\\-]*', re.MULTILINE)\n",
    "        stop = False\n",
    "        count=0\n",
    "        start_index = item_start_index\n",
    "        while True:\n",
    "            count+=1\n",
    "            if stop == True:\n",
    "                break\n",
    "            if count>15:\n",
    "                return '', -1\n",
    "            match = pattern.search(file_text, pos=start_index+10)\n",
    "            if match:\n",
    "                stop_index = match.start()\n",
    "                item_stop_index = stop_index\n",
    "                stopcheck = stop_index\n",
    "                if file_text[item_stop_index]=='\\n':\n",
    "                    stopcheck+=1\n",
    "                matching_line = None\n",
    "                current_index = 0\n",
    "                for i, line in enumerate(lines):\n",
    "                    line_length = len(line)\n",
    "                    if i < len(lines) - 1:\n",
    "                        line_length += 1  \n",
    "                    if current_index <= stopcheck < current_index + line_length:\n",
    "                        matching_line = line\n",
    "                        break\n",
    "                    current_index += line_length\n",
    "                line = matching_line\n",
    "                if line==None:\n",
    "                    start_index = stop_index\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        if '\"' not in line and '“' not in line and '”' not in line and '...' not in line and ',' not in line:\n",
    "                            item_stop_index = stop_index\n",
    "                            item_text  = file_text[item_start_index:item_stop_index]\n",
    "                            stop = True\n",
    "                            return item_text, item_stop_index \n",
    "                        else:\n",
    "                            start_index = stop_index \n",
    "                            continue\n",
    "                    except:\n",
    "                        start_index = stop_index\n",
    "                        continue\n",
    "            else:\n",
    "                break\n",
    "        return '', -1\n",
    "    else:\n",
    "        return '', -1\n",
    "\n",
    "def clean_data(text):\n",
    "    #text = re.sub(r'<.*?>', '', text)\n",
    "    #text = re.sub(r'-\\d+-', '', text)\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e41fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = {\n",
    "    'ITEM 1.':\"Item 1. Business\",\n",
    "    'ITEM 1A.': \"Item 1A. Risk Factors\",\n",
    "    'ITEM 1B.' : \"Item 1B. Unresolved Staff Comments\",\n",
    "    'ITEM 1C.' : \"Item 1C. Cybersecurity\",\n",
    "    'ITEM 2.': \"Item 2. Properties\",\n",
    "    'ITEM 3.' : \"Item 3. Legal Proceedings\",\n",
    "    'ITEM 4.' : \"Item 4. Mine Safety Disclosures\",\n",
    "    'ITEM 5.': \"Item 5. Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities\",\n",
    "    'ITEM 7.' : \"Item 7. Management’s Discussion and Analysis of Financial Condition and Results of Operations\",\n",
    "    'ITEM 7A.' : \"Item 7A. Quantitative and Qualitative Disclosures About Market Risk\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1723b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#run this only once before starting the manual cleaning\n",
    "def extract_info_from_url(row):\n",
    "    if pd.notna(row['Item 1. Business']) and row['Item 1. Business'] != '':\n",
    "        return row\n",
    "    url = row['URL']\n",
    "    try:\n",
    "        max_retries = 3\n",
    "        retry_delay = 3 \n",
    "        for _ in range(max_retries):\n",
    "            try:\n",
    "                headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "                response = requests.get(url, headers=headers)\n",
    "                response.raise_for_status()\n",
    "            except HTTPError as e:\n",
    "                if e.response.status_code == 503:\n",
    "                    print(f\"Failed to retrieve content. Status code: {e.response.status_code}\")\n",
    "                    time.sleep(retry_delay)  \n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"HTTP error: {e}\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                break\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            text = response.text \n",
    "            text = html.unescape(text)\n",
    "            text=text.replace('&nbsp;', '')\n",
    "            text=text.replace('&#151;', '-')\n",
    "            text=text.replace('&#160;', '-')\n",
    "            text=text.replace('\\xa0', ' ')\n",
    "            # Part word remove  pattern \n",
    "            pattern_Part = re.compile(r'part\\s*(II|I)\\s*([.,\\s]?)\\s*', re.IGNORECASE)\n",
    "            text = re.sub(pattern_Part, '' ,text)\n",
    "            # no.s in words \n",
    "            number_mapping1 = {'One': '1', 'Two': '2', 'Three': '3', 'Four': '4', 'Five': '5', 'Seven': '7'}\n",
    "            number_mapping2 = {'ONE': '1', 'TWO': '2', 'THREE': '3', 'FOUR': '4', 'FIVE': '5', 'SEVEN': '7'}\n",
    "\n",
    "            converted_text = text\n",
    "\n",
    "            for word, number in number_mapping1.items():\n",
    "                converted_text = converted_text.replace(word, number)\n",
    "\n",
    "            for word, number in number_mapping2.items():\n",
    "                converted_text = converted_text.replace(word, number)\n",
    "\n",
    "            text = converted_text\n",
    "\n",
    "            part_url=['https://www.sec.gov/Archives/edgar/data/23197/0001169232-02-002122.txt','https://www.sec.gov/Archives/edgar/data/70145/0000070145-03-000112.txt' ,'https://www.sec.gov/Archives/edgar/data/70793/0000910647-03-000404.txt','https://www.sec.gov/Archives/edgar/data/1014052/0000096313-03-000216.txt','https://www.sec.gov/Archives/edgar/data/38777/0000038777-03-000693.txt', 'https://www.sec.gov/Archives/edgar/data/1014052/0001015402-04-004698.txt','https://www.sec.gov/Archives/edgar/data/1046050/0000939057-04-000463.txt','https://www.sec.gov/Archives/edgar/data/1283858/0000939057-04-000485.txt','https://www.sec.gov/Archives/edgar/data/717724/0000717724-04-000008.txt','https://www.sec.gov/Archives/edgar/data/1046050/0000939057-05-000360.txt','https://www.sec.gov/Archives/edgar/data/809933/0000809933-05-000019.txt','https://www.sec.gov/Archives/edgar/data/1046050/0000939057-07-000444.txt','https://www.sec.gov/Archives/edgar/data/1305014/0001305014-07-000308.txt','https://www.sec.gov/Archives/edgar/data/1046050/0000939057-08-000478.txt','https://www.sec.gov/Archives/edgar/data/1305014/0001305014-08-000364.txt','https://www.sec.gov/Archives/edgar/data/1046050/0000939057-09-000370.txt','https://www.sec.gov/Archives/edgar/data/1305014/0001305014-09-000097.txt','https://www.sec.gov/Archives/edgar/data/1046050/0000939057-10-000384.txt','https://www.sec.gov/Archives/edgar/data/1305014/0001305014-10-000079.txt']\n",
    "\n",
    "            text = re.sub(r'<!--[\\s\\S]*?-->|<[^>]*>', '\\n', text)\n",
    "            emptypattern = re.compile(r'^\\s*$', re.MULTILINE)\n",
    "            text = re.sub(emptypattern, '', text)\n",
    "            lines = [line.lstrip() for line in text.split('\\n')]\n",
    "            text = '\\n'.join(lines)\n",
    "            flag = False\n",
    "            table_stop_index = 0\n",
    "            table_stop_pattern = re.compile(r'Signatures', re.IGNORECASE)\n",
    "            table_start_index = text.lower().find(\"table of contents\")\n",
    "            if table_start_index!=-1: \n",
    "                start_index = 0\n",
    "                while True:\n",
    "                    toc_index = text.lower().find(\"table of contents\", start_index)\n",
    "                    if toc_index==-1:\n",
    "                        toc_index = text.lower().find(\"index to annual report on form 10-k\", start_index)\n",
    "                    if toc_index==-1:\n",
    "                        toc_index = text.lower().find(\"index\", start_index)\n",
    "                    if toc_index==-1:\n",
    "                        toc_index = text.lower().find(\"contents\", start_index)\n",
    "                    if flag==True:\n",
    "                        break\n",
    "                    if toc_index != -1:\n",
    "                        match = table_stop_pattern.search(text, pos=toc_index+1)\n",
    "                        if match:\n",
    "                            table_stop_index = match.start()\n",
    "                            content_after_toc = text[toc_index:table_stop_index]\n",
    "                            content_lines = content_after_toc.split('\\n')\n",
    "                            found_items = [re.search(r'(?i)Item\\s*[0-9A-C]+\\s*[.:\\\\-]*', line) for line in content_lines]\n",
    "                            if any(found_items):\n",
    "                                table_start_index = toc_index\n",
    "                                flag=True\n",
    "                                break \n",
    "                            else:\n",
    "                                start_index = toc_index + 10\n",
    "                        else:\n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                if len(text[table_start_index:table_stop_index])<=3500 and table_stop_index!=0:\n",
    "                    text = text[:table_start_index] + text[table_stop_index:]\n",
    "                   \n",
    "            table_pattern =r'\\s*Item\\s*[0-9A-C]+\\s*[.:\\\\-]*\\s+[A-Za-z0-9\\s\\'\"\\-,]+\\.*\\s*\\.{3,}\\s*\\d+$'\n",
    "            part_pattern = r'\\bPART [I1]\\b'\n",
    "            part_start = []\n",
    "            for match in re.finditer(part_pattern, text, re.IGNORECASE):\n",
    "                part_start.append(match.start())\n",
    "            if len(part_start)>=2:\n",
    "                if part_start[1]-part_start[0]<=2500 or url in part_url:\n",
    "                    if text[part_start[0]:part_start[1]].lower().count('item')>10:\n",
    "                        text = text[part_start[1]:]\n",
    "            text=text.replace('Item l.', 'Item 1.')\n",
    "            text=text.replace('ITEM l.', 'Item 1.')\n",
    "            \n",
    "            index=0\n",
    "            index_save=0\n",
    "            for item in items:\n",
    "                item_text, index= find_item_text(text, item, index_save)\n",
    "                if index!=-1:\n",
    "                    index_save = index\n",
    "                if item_text!= None:\n",
    "                    item_text = clean_data(item_text)\n",
    "                    item1count= 0 \n",
    "                    if len(item_text)<500 and item=='ITEM 1.' and not re.search(r'(?i)\\b(omitted|not applicable|not|none|pursuant|relief)\\b[.,;!?]*', item_text):\n",
    "                        while True:\n",
    "                            item1count+=1\n",
    "                            if item1count>7:\n",
    "                                break\n",
    "                            if len(item_text)<500 and item=='ITEM 1.' and not re.search(r'(?i)\\b(omitted|not applicable|not|none|pursuant|relief)\\b[.,;!?]*', item_text):\n",
    "                                item_text, index= find_item_text(text, item, index_save)\n",
    "                                row[items[item]] = item_text\n",
    "                                if index!=-1:\n",
    "                                    index_save = index\n",
    "                            else:\n",
    "                                break\n",
    "                    else:\n",
    "                        row[items[item]] = item_text\n",
    "                else:\n",
    "                    row[items[item]] = ' '\n",
    "        \n",
    "        else:\n",
    "            print(f\"Failed to retrieve content. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(url, e)\n",
    "    return row\n",
    "\n",
    "tqdm.pandas()\n",
    "# filtered_df = pd.read_csv(r'D:\\Inter Mnaggi\\Mengge_Li\\10-K_2008_Q.csv') #change the path\n",
    "# filtered_df= filtered_df.progress_apply(extract_info_from_url, axis=1)\n",
    "# filtered_df.to_csv(r'D:\\Inter Mnaggi\\Mengge_Li\\10-K_2008_Q.csv',index=False)\n",
    "# filtered_df.to_excel(r'D:\\Inter Mnaggi\\Mengge_Li\\10-K_2008_Q.xlsx', index=False)\n",
    "# print('New CSV and Excel Generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa18fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This will generate a csv file of all the text present in the URL. Generated CSV is used for copying and pasting the required items.\n",
    "Required items are :\n",
    "Item 1. Business,\t\n",
    "Item 1A. Risk Factors,\t\n",
    "Item 1B. Unresolved Staff Comments, \n",
    "Item 1C. Cybersecurity,\t\n",
    "Item 2. Properties,\t\n",
    "Item 3. Legal Proceedings, \n",
    "Item 4. Mine Safety Disclosures,\t\n",
    "Item 5. Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities\t\n",
    "Item 7. Management’s Discussion and Analysis of Financial Condition and Results of Operations,\t\n",
    "Item 7A. Quantitative and Qualitative Disclosures About Market Risk  or \n",
    "7A. Critical Accounting Policies and New Accounting Pronouncements\n",
    "\n",
    "Item 6 SELECTED FINANCIAL DATA\n",
    "\n",
    "Item 8 FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA\n",
    "'''\n",
    "def extract_info_from_url(url):\n",
    "    try:\n",
    "        max_retries = 3\n",
    "        retry_delay = 3 \n",
    "        for _ in range(max_retries):\n",
    "            try:\n",
    "                headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "                response = requests.get(url, headers=headers)\n",
    "                response.raise_for_status()\n",
    "            except HTTPError as e:\n",
    "                if e.response.status_code == 503:\n",
    "                    print(f\"Failed to retrieve content. Status code: {e.response.status_code}\")\n",
    "                    time.sleep(retry_delay)  \n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"HTTP error: {e}\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                break\n",
    "        #headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "        #response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            text = response.text \n",
    "            #soup = BeautifulSoup(text, 'html.parser')\n",
    "            #text = soup.get_text()\n",
    "            text = html.unescape(text)\n",
    "            text=text.replace('&nbsp;', '')\n",
    "            text=text.replace('&#151;', '-')\n",
    "            text=text.replace('&#160;', '-')\n",
    "            text=text.replace('\\xa0', ' ')\n",
    "            # Part remove word pattern \n",
    "            pattern_Part = re.compile(r'part\\s*(II|I)\\s*([.,\\s]?)\\s*', re.IGNORECASE)\n",
    "            text = re.sub(pattern_Part, '' ,text)\n",
    "#             number_mapping1 = {'One': '1', 'Two': '2', 'Three': '3', 'Four': '4', 'Five': '5', 'Seven': '7'}\n",
    "#             number_mapping2 = {'ONE': '1', 'TWO': '2', 'THREE': '3', 'FOUR': '4', 'FIVE': '5', 'SEVEN': '7'}\n",
    "\n",
    "\n",
    "#             converted_text = text\n",
    "\n",
    "#             for word, number in number_mapping1.items():\n",
    "#                 converted_text = converted_text.replace(word, number)\n",
    "\n",
    "#             for word, number in number_mapping2.items():\n",
    "#                 converted_text = converted_text.replace(word, number)\n",
    "\n",
    "#             text = converted_text\n",
    "            part_url=['https://www.sec.gov/Archives/edgar/data/23197/0001169232-02-002122.txt','https://www.sec.gov/Archives/edgar/data/70145/0000070145-03-000112.txt' ,'https://www.sec.gov/Archives/edgar/data/70793/0000910647-03-000404.txt','https://www.sec.gov/Archives/edgar/data/1014052/0000096313-03-000216.txt','https://www.sec.gov/Archives/edgar/data/38777/0000038777-03-000693.txt', 'https://www.sec.gov/Archives/edgar/data/1014052/0001015402-04-004698.txt','https://www.sec.gov/Archives/edgar/data/1046050/0000939057-04-000463.txt','https://www.sec.gov/Archives/edgar/data/1283858/0000939057-04-000485.txt','https://www.sec.gov/Archives/edgar/data/717724/0000717724-04-000008.txt','https://www.sec.gov/Archives/edgar/data/1046050/0000939057-05-000360.txt','https://www.sec.gov/Archives/edgar/data/809933/0000809933-05-000019.txt','https://www.sec.gov/Archives/edgar/data/1046050/0000939057-07-000444.txt','https://www.sec.gov/Archives/edgar/data/1305014/0001305014-07-000308.txt','https://www.sec.gov/Archives/edgar/data/1046050/0000939057-08-000478.txt','https://www.sec.gov/Archives/edgar/data/1305014/0001305014-08-000364.txt','https://www.sec.gov/Archives/edgar/data/1046050/0000939057-09-000370.txt','https://www.sec.gov/Archives/edgar/data/1305014/0001305014-09-000097.txt','https://www.sec.gov/Archives/edgar/data/1046050/0000939057-10-000384.txt','https://www.sec.gov/Archives/edgar/data/1305014/0001305014-10-000079.txt']\n",
    "\n",
    "            text = re.sub(r'<!--[\\s\\S]*?-->|<[^>]*>', '\\n', text)\n",
    "            emptypattern = re.compile(r'^\\s*$', re.MULTILINE)\n",
    "            text = re.sub(emptypattern, '', text)\n",
    "            lines = [line.lstrip() for line in text.split('\\n')]\n",
    "            text = '\\n'.join(lines)\n",
    "            flag = False\n",
    "            table_stop_index = 0\n",
    "            table_stop_pattern = re.compile(r'Signatures', re.IGNORECASE)\n",
    "            table_start_index = text.lower().find(\"table of contents\")\n",
    "            if table_start_index!=-1: \n",
    "                start_index = 0\n",
    "                while True:\n",
    "                    toc_index = text.lower().find(\"table of contents\", start_index)\n",
    "                    if toc_index==-1:\n",
    "                        toc_index = text.lower().find(\"index to annual report on form 10-k\", start_index)\n",
    "                    if flag==True:\n",
    "                        break\n",
    "                    if toc_index != -1:\n",
    "                        match = table_stop_pattern.search(text, pos=toc_index+1)\n",
    "                        if match:\n",
    "                            table_stop_index = match.start()\n",
    "                            content_after_toc = text[toc_index:table_stop_index]\n",
    "                            content_lines = content_after_toc.split('\\n')\n",
    "                            found_items = [re.search(r'(?i)Item\\s*[0-9A-C]+\\s*[.:\\\\-]*', line) for line in content_lines]\n",
    "                            if any(found_items):\n",
    "                                table_start_index = toc_index\n",
    "                                flag=True\n",
    "                                break \n",
    "                            else:\n",
    "                                start_index = toc_index + 10\n",
    "                        else:\n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                if len(text[table_start_index:table_stop_index])<=3500 and table_stop_index!=0:\n",
    "                    text = text[:table_start_index] + text[table_stop_index:]\n",
    "                   \n",
    "            table_pattern =r'\\s*Item\\s*[0-9A-C]+\\s*[.:\\\\-]*\\s+[A-Za-z0-9\\s\\'\"\\-,]+\\.*\\s*\\.{3,}\\s*\\d+$'\n",
    "            part_pattern = r'\\bPART [I1]\\b'\n",
    "            part_start = []\n",
    "            for match in re.finditer(part_pattern, text, re.IGNORECASE):\n",
    "                part_start.append(match.start())\n",
    "            if len(part_start)>=2:\n",
    "                if part_start[1]-part_start[0]<=2500 or url in part_url:\n",
    "                    if text[part_start[0]:part_start[1]].lower().count('item')>10:\n",
    "                        text = text[part_start[1]:]\n",
    "            text=text.replace('Item l.', 'Item 1.')\n",
    "            text=text.replace('ITEM l.', 'Item 1.')\n",
    "            ctext=clean_data(text)\n",
    "            correct_df = pd.DataFrame({'Cleaned_Text': [ctext]})\n",
    "            correct_df.to_csv(\"correct.csv\", index=False)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve content. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(url, e)\n",
    "   \n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "#change the url only. URL for file having incorrect or no extraction.\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/71180/0000741508-08-000011.txt'\n",
    "extract_info_from_url(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
